name: Daily GBIF update

on:
  schedule:
    - cron: "17 3 * * *"  # daily, UTC
  workflow_dispatch: {}

permissions:
  contents: write

jobs:
  build_db:
    name: Build / update SQLite DB
    runs-on: ubuntu-latest
    timeout-minutes: 360
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run DB-only pipeline (GBIF download + load SQLite)
        env:
          GBIF_USER: ${{ secrets.GBIF_USER }}
          GBIF_PWD: ${{ secrets.GBIF_PWD }}
          GBIF_EMAIL: ${{ secrets.GBIF_EMAIL }}
          PYTHONUNBUFFERED: "1"
        run: |
          python -u tools/run_daily_update.py --db-only

      - name: Upload DB checkpoint artifact
        uses: actions/upload-artifact@v4
        with:
          name: dwca-sqlite
          path: data/dwca.sqlite
          retention-days: 7

      - name: Commit outputs (if changed) and push
        run: |
          set -euxo pipefail
      
          git config user.name "gbif-bot"
          git config user.email "gbif-bot@users.noreply.github.com"
      
          git add data/gbif_state.json data/plants_resolved.json data/taxon_cache.json data/occurrences_compact.json.gz || true
      
          if git diff --cached --quiet; then
            echo "No changes."
            exit 0
          fi
      
          git commit -m "chore(state): daily GBIF refresh"
      
          # Sync with remote to avoid "fetch first"
          git fetch origin main
          git rebase origin/main
      
          git push origin HEAD:main


  export_and_release:
    name: Export compact dataset + publish Release asset
    needs: build_db
    runs-on: ubuntu-latest
    timeout-minutes: 360
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download DB checkpoint artifact
        uses: actions/download-artifact@v4
        with:
          name: dwca-sqlite
          path: data

      - name: Run export-only pipeline (creates occurrences_compact.json.gz)
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          python -u tools/run_daily_update.py --export-only

      - name: Publish / update Release asset (latest)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python -u tools/publish_release_asset.py \
            --tag latest \
            --title "Latest GBIF export" \
            --notes "Auto-generated data export. Assets: occurrences_compact.json.gz (+ optional stats/thumbs)." \
            --dataset data/occurrences_compact.json.gz \
            --stats data/stats_summary.json
